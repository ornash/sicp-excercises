#+TITLE: Notes on Structure and Interpretation of Computer Programs
#+STARTUP: indent
[[./sicp.html][HTML Export]]
[[https://github.com/ornash/book-notes/blob/master/sicp.org][Github Page]]


* Chapter 1 : Building Abstractions with Procedures
** Computational Process
Computational processes are abstract beings that inhabit computers. As they evolve, processes manipulate other abstract
things called data. The evolution of a process is directed by a pattern of rules called a program. People create
programs to direct processes.

** Elements of Programming
Every powerful language has three mechanisms for expressing processes:
1. *primitive expressions*, which represent the simplest entities the language is concerned with,
2. *means of combination*, by which compound elements are built from simple ones, and
3. *means of abstraction*, by which compound elements can be named and manipulated as units.

** Procedure/Program Application/Evaluation
A substition model is used for procedure application. There are two evalution methods for procedure application:
1. *Applicative-order evaluation*: evaluate the arguments and then apply. An argument is evaluated only once but that
   evaluation is going to be wasteful if the argument isn't used. Scheme uses applicative-order evaluation.
2. *Normal-order evaluation*: fully expand and then reduce/evaluate i.e. obtain expression involving only primitives and
   then evaluate. An argument isn't evaluated until it is used but it might be evaluated more than once after full expansion.

Check out exercise [[https://github.com/ornash/sicp-excercises/tree/master/chapter-1/20-applicative-vs-normal][1.20]] to understand how this choice affects evaluation.

** Procedures and the Processes They Generate
We now know the elements of programming, but that is not enough to say that we know how to program. In order to become
expert programmer, we must learn to visualize the processes generated by various types of procedures. We must also learn
to calculate the rates at which the procedure consumes the computational resources of time and space.

*** Recursive Procedures
Evaluate and visualize the processes generated by following *recursive procedures* in terms of time and space.
#+BEGIN_SRC scheme
;;Recursive procedure that generates *recursive* process.
(define (factorial n)
  (if (= n 1)
    1
    (* n (factorial (- n 1)))))

;;Recursive procedure that generates *iterative* process.
(define (factorial-iter n)
  (define (iter product counter)
    (if (> counter n)
      product
      (iter (* counter product)
            (+ counter 1))))
  (iter 1 1))  
#+END_SRC

When we consider the "shapes" of the two processes, we see that they evolve quite differently. One grows and shrinks
while other is lean. Carrying out the *recursive* process requires that the interpreter keep track of some *hidden*
information and operations to be performed later on. On the other hand, carrying out the *iterative* process does not
require processing any hidden information, its state can be summarized by fixed number of state variables in the
procedure.

The implementation that generates iterative process is called as *tail recursive* implementation. In tail recursive
implementation the last statement is a call to recursive procedure itself with no work left to be performed in current
procedure call; therefore, compiler can optimize such call by replacing current stack frame instead of creating a new
one.

*** Tree Recursion
Evaluate and visualize the processes generated by following *recursive procedures* in terms of time and space.
#+BEGIN_SRC scheme
;;Recursive procedure that generates *tree recursive* process.
(define (fib n)
  (cond ((= n 0) 0)
        ((= n 1) 1)
        (else (+ (fib (- n 1)) (fib (- n 2))))
  ))

;;Recursive procedure that generates *iterative* process.
(define (fib-iter n)
  (define (iter a b count)
    (cond ((= n 0) 0)
          ((= n 1) 1)
          ((= count n) a)
          (else (iter (+ a b) a (+ count 1)))))
   (iter 1 0 1))
#+END_SRC

Tree recursion is a powerful tool to operate on hierarchically structured data.

*** Decomposition
Functional procedures encourage reuse because every computation unit is defined as a function which can be used somewhere
else. Decomposition into units also helps transform one implementation into other quickly.

*** Notes
- Functional programming makes you think in terms of functions/tasks and not in terms of data/elements e.g. Compare the
  difference in implementation of the following in imperative programming. Use wishful thinking and abstraction to
  program better and faster.
#+BEGIN_SRC scheme
(define (smallest-divisor n)
  (find-divisor n 2))

(define (find-divisor n test-divisor)
  (cond ((> (square test-divisor) n) n)
        ((divides? test-divisor n) test-divisor)
        (else (find-divisor n (+ test-divisor 1)))))

(define (divides? denom numer)
  (= (remainder numer denom) 0))
#+END_SRC
- Be careful of recursive procedures, subtle changes in code can result in huge difference in time
  complexity. e.g. Check exercise [[./chapter-1/22-search-primes/22-search-primes.scm][1.25]] and [[./chapter-1/22-search-primes/22-search-primes.scm][1.26]].
** Formulating Abstractions with Higher Order Procedures
Procedures that manipulate procedures are called higher-order procedures i.e. procedures that can accept procedures as
arguments or return procedures as values. As shown below higher-order procedures permit us to manipulate general methods
to create further abstractions.

*** Procedure as Argument
#+BEGIN_SRC scheme
(define (sum operation a next b)
  (if (> a b)
      0
      (+ (operation a)
         (sum operation (next a) next b))))

(define (inc n) (+ n 1))

(define (cube x) (* x x x))

(define (sum-cubes a b)
  (sum cube a inc b))

(define (identity x) x)

(define (sum-integers a b)
  (sum identity a inc b))
#+END_SRC

Note: This simple feature of allowing procedures as arguments is extremely powerful and helps us to identify and share
common underlying patterns in various programs thereby reducing overall code and effort. It allows to create higher
levels of abstraction helping us think better and faster. This is either not possible or very cumbersome in other
languages. 

*** Constructing Procedures Using Lambda
(lambda (<formal-parameters>) <body>)

#+BEGIN_SRC scheme
(lambda (x) (+ x 1))

(define (sum-cubes a b)
  (sum cube a (lambda (x) (+ x 1)) b))
#+END_SRC

- Lambda function's body is usually defined in terms existing functions.
- Lambda function can itself define and use other lambda functions in its body.
- Lambda function can itself expect other functions as parameters and use them in its body.
- Functions can define lambdas on the fly and apply them.
- Functions can define lambdas on the fly and pass them as arguments.
- When a function receives a lambda function as parameter it gets a name and that named function can itself be applied
  and evaluated.
*** Using let To Create Local Variable
Let allows one to bind variables as locally as possible to where they are to be used. The general form of a let
expression is

(let ((<var1> <exp1>)
      (<var2> <exp2>)
      ...
      (<varN> <expN>))
  <body>)
  
which can be thought of as saying

let <var1> have the value <exp1> and
    <var2> have the value <exp2> and
    ...
    <varN> have the value <expN>
  in <body>
#+BEGIN_SRC scheme
(define (f x y)
  (let ((a (+ 1 (* x y)))
        (b (- 1 y)))
    (+ (* x (square a))
       (* y b)
       (* a b))))
#+END_SRC

*** Procedures as Returned Values
Procedures can be returned using lambda as follows

#+BEGIN_SRC scheme
(define (get-average-reduction-function-using-function f)
  (lambda (x) 
    (average x (f x))))

((get-average-reduction-function-using-function square) 10)

;;This returns 55, which is the average of 10 and (square 10)
#+END_SRC

*** Abstraction and First Class Procedures
We know that compound procedures are a crucial abstraction mechanism, because they permit us to express general methods
of computing as explicit elements in our programming language e.g. (* x x x) can be represented with a general method
called (cube x). Higher-order procedures permit us to manipulate these general methods to create further abstractions.

As programmers, we should be alert to opportunities to identify the underlying abstractions in our programs and to build
upon them and generalize them to create more powerful abstractions. This is not to say that one should always write
programs in the most abstract way possible; expert programmers know how to choose the level of abstraction appropriate
to their task. But it is important to be able to think in terms of these abstractions, so that we can be ready to apply
them in new contexts. The significance of higher-order procedures is that they enable us to represent these abstractions
explicitly as elements in our programming language, so that they can be handled just like other computational elements.

In general, programming languages impose restrictions on the ways in which computational elements can be
manipulated. Elements with the fewest restrictions are said to have first-class status. Some of the “rights and
privileges” of first-class elements are:

1. They may be named by variables.
2. They may be passed as arguments to procedures.
3. They may be returned as the results of procedures.
4. They may be included in data structures.

*Scheme/Lisp, unlike other common programming languages, awards procedures full first-class status.* This poses
challenges for efficient implementation, but the resulting gain in expressive power is enormous. Chapter 4 highlights
these challenges and provides solutions to deal with them.

*** Notes
- Higher-order procedures don't just allow us to manipulate general methods of computation, they also allow us to reason
  in terms of those general methods thereby enhancing the power of programming langauge to express complex ideas as well
  as the power of programmer to reason about those complex ideas.
- When you create abstractions keep in mind that the deeper they are the more difficult they are for the reader to
  understand. Keep them shallow if possible. I can think of one solution to this problem, let programmers provide as
  deep abstractions as they want while writing, write a tool that unravels the deep abstraction and shows a possible
  expanded view of the same code while reading so that it is easy to understand for a new programmer. Basically the call
  stack has to reside somewhere i.e. either in the brain of programmer or in front of the programmer on the screen, the
  cognitive load on the programmers must be reduced so that they can think in higer levels of abstractions and dive into
  abstractions when necessary. See [[./chapter-1/][chapter-1]], Exercise [[./chapter-2/29-binary-mobile/29-binary-mobile.scm][2.29]].
- If you do have to create deep abstractions ensure that they are named appropriately so that programmer doesnt have to
  unravel them to understand the code, names should be self-explanatory throughout. The cognitive load should be
  reduced. See Exercise [[./chapter-2/29-binary-mobile/29-binary-mobile.scm][2.29]].
- The goal of writing abstractions is to try to arrive at a state where the abstraction can be used as: f(g(h(x),y))
  i.e. a chain of function calls.
- With practice, you should be able to traverse up and down the call tree to manipulate and define the right
  abstraction.
- As the number of higher order functions in the call tree increase, it becomes difficult to keep track of variables so
  ensure that you always use good procedure names and unique variable names so that the code makes sense in
  future. See Exercise [[./chapter-1/42-compose/42-compose.scm][1.46]].

** Miscellaneous
*** Writing Recursive Programs
- Think in terms of smallest/simplest units of computation that is already available or you can achieve, then assemble
  small units to build larger units. Start with the base case and build up.
- Express your computation in as less words as possible, less code leads to less bugs.
- Do not think of simplifying your recursive program to generate an iterative process instead of recursive process
  immediately. First write a program that generates recusive and then improve it so that it generates iterative
  process.
*** Advantages of Recursive Programs
- Compare the amount of code written for recursive/functional programs with equivalent code in procedural programming,
  *When you think differently, you write less code.* 
- You are able to write full fledged programs by only knowing about few core concepts.
- It forces you to write code in small units which ultimately help identify patterns.
- Identified patterns can further be used to define higher-order procedures.


* Chapter 2 : Building Abstractions with Data
Last chapter focused on building abstractions by combining procedures to form compound procedures. This chapter will
focus on another key aspect of building abstractions which involves combining data objects to form compound data.

Why do we want compound data in a programming language?
- For the same reasons that we want compound procedures:
  - to elevate the conceptual level at which we can design our programs,
  - to increase the modularity of our designs,
  - and to enhance the expressive power of our language.

Notes:
- The primary goal of a programming language is to allow the programmer to think better. If the programmer thinks better
  the code will automatically be better. Similary, for software, it shold allow its user to think and therefore work
  better.

** Data Abstraction
The general technique of isolating the parts of a program that deal with how data objects are *represented* from the
parts of a program that deal with how data objects are *used* is called data abstraction.

Programming languages usually provide some primitive data objects and operations that can be used to form compound
data. But *compound data* can also be formed using just procedures which blurs the distinction between data and
procedures. Both should be treated as mechanisms to achieve abstraction.

*** Data Abstraction
- Data abstraction is a methodology that enables us to isolate how a compound data object is used from the details of
  how it is constructed from more primitive data objects.
- Structure the programs that are going to use compound data so that they operate on *abstract data*.
- At the same time, define a *concrete representation* that is independent of its usage.
- The interface between these two parts of our system will be a set of procedures, called *selectors and constructors*,
  that implement the *abstract data* in terms of the *concrete representation*.
- e.g. an implementation of rational numbers.
#+BEGIN_SRC scheme
(define (make-rat n d) (cons n d))
(define (numer x) (car x))
(define (denom x) (cdr x))
#+END_SRC
- An alternative approach that can be implemented later. Data abstraction allows changing it because users are only
  aware of the constructor make-rat, and selectors numer and denom.
#+BEGIN_SRC scheme
(define (make-rat n d)
  (let ((g (gcd n d)))
    (cons (/ n g) 
          (/ d g))))
(define (numer x) (car x))
(define (denom x) (cdr x))
#+END_SRC

*** Abstraction Barriers
- Data abstraction forms levels and procedures at each level are the interfaces that define the *abstraction barriers*
  and connect the different levels.
- The data-abstraction methodology gives us a way to defer some implementation/representation decisions without losing
  the ability to make progress on the rest of the system.
- e.g. we can change above implementation later as follows:
#+BEGIN_SRC scheme
(define (make-rat n d)
  (cons n d))

(define (numer x)
  (let ((g (gcd (car x) (cdr x))))
    (/ (car x) g)))

(define (denom x)
  (let ((g (gcd (car x) (cdr x))))
    (/ (cdr x) g)))
#+END_SRC

*** What Is Meant by Data?
- It is not enough to say “whatever is implemented by the given selectors and constructors.”
- We can think of data as defined by *some collection of selectors and constructors*, *together with specified
  conditions that these procedures must fulfill in order to be a valid representation*.
- For e.g. If we construct a rational number x from a pair of integers n and d, we need to guarantee that extracting the
  numer and the denom of x and dividing them should yield the same result as dividing n by d.
- An alternative implementation of "cons" could be:
#+BEGIN_SRC scheme
(define (cons x y)
  (define (dispatch m)
    (cond ((= m 0) x)
          ((= m 1) y)
          (else 
           (error "Argument not 0 or 1:
                   CONS" m))))
  dispatch)

(define (car z) (z 0))
(define (cdr z) (z 1))
#+END_SRC
- Our implementation of rational numbers is unaffected by this change to "cons".
- Note that this blurs the line between procedures and data. Thus, what matters is whether the constructors and
  selectors satisfy the conditions of the data abstraction not how they are implemented or represented.
- The data representation optimization decisions can be pushed to a later time if required.


** Hierarchical Data and the Closure Property
The ability to create pairs whose elements are pairs is the essence of list structure's importance as a representational
tool.  We refer to this ability as the "closure property" of 'cons'.

Closure is the key to power in any means of combination because it permits us to create "hierarchical"
structures--structures made up of parts, which themselves are made up of parts, and so on.

*** Representing Sequences
Scheme has list operation to represent sequences.

(list <A_1> <A_2> ... <A_N>)

is equivalent to

(cons <A_1> (cons <A_2> (cons ... (cons <A_N> nil) ...)))

**** List Operations
"cdr down and cons up"
#+BEGIN_SRC scheme
(define (length items)
    (if (null? items)
        0
        (+ 1 (length (cdr items)))))

(define (append list1 list2)
    (if (null? list1)
        list2
        (cons (car list1)
              (append (cdr list1) list2))))
#+END_SRC

**** Mapping Over Lists
#+BEGIN_SRC scheme
(define (scale-list items factor)
    (if (null? items)
        nil
        (cons (* (car items) factor)
              (scale-list (cdr items) factor))))
#+END_SRC

We can keep doing "cdr down and cons up" but we can abstract this general idea and capture it as a common pattern
expressed as a higher-order procedure called "map".

#+BEGIN_SRC scheme
(define (map proc items)
    (if (null? items)
        nil
        (cons (proc (car items))
              (map proc (cdr items)))))

(define (scale-list items factor)
    (map (lambda (x) (* x factor))
         items))
#+END_SRC

'Map' is an important construct, not only because it captures a common pattern, but because it establishes a higher
level of  abstraction in dealing with lists.  In the original definition of 'scale-list', the recursive structure of the
program draws attention to the element-by-element processing of the list.  Defining 'scale-list' in terms of 'map'
suppresses that level of detail and emphasizes that scaling transforms a list of elements to a list of results.  The
difference between the two definitions is not that the computer is performing a different process (it isn't) but that we
think about the process differently. In effect, 'map' helps establish an abstraction barrier.

Note: Creating abstraction barriers is important to help programmers think better. The implementation of the abstraction
itself can be optimized later if requried. We are writing programs for computers as well as other programmers.

*** Hierarchical Structures
The representation of sequences in terms of lists generalizes naturally to represent sequences whose elements may
themselves be sequences. Another way to think of sequences whose elements are sequences is as "trees".

Recursion is a natural tool for dealing with tree structures, since we can often reduce operations on trees to
operations on their branches, which reduce in turn to operations on the branches of the branches, and so on, until we
reach the leaves of the tree. 

#+BEGIN_SRC scheme
(define (count-leaves x)
    (cond ((null? x) 0)
          ((not (pair? x)) 1)
          (else (+ (count-leaves (car x))
                   (count-leaves (cdr x))))))
#+END_SRC

**** Mapping Over Trees
The recursive plan for 'scale-tree' is similar to the one for 'count-leaves':
#+BEGIN_SRC scheme
(define (scale-tree tree factor)
    ;;(display tree)
    ;;(newline)
    (cond ((null? tree) '())
          ((not (pair? tree)) (* tree factor))
          (else (cons (scale-tree (car tree) factor)
                      (scale-tree (cdr tree) factor)))))
#+END_SRC

Just as 'map' is a powerful abstraction for dealing with sequences, 'map' together with recursion is a powerful
abstraction for dealing with trees. Another way to implement 'scale-tree' is to regard the tree as a sequence of
sub-trees and use 'map'.

#+BEGIN_SRC scheme
;;Adding implementation of map here for reference.
(define (map proc items)
    ;;(display "my-map")
    ;;(display items)
    ;;(newline)
    (if (null? items)
        '()
        (cons (proc (car items))
              (map proc (cdr items)))))

(define (scale-tree tree factor)
   ;;(display "scale-tree-map ")
   ;;(display tree)
   ;;(newline)
   (map (lambda (sub-tree)
            ;;(display "lambda ")
	    ;;(display sub-tree)
	    ;;(newline)
            (if (not (pair? sub-tree))
                (* sub-tree factor)
                (scale-tree sub-tree factor)))
        tree))
#+END_SRC

Note: Both approaches above perform "cdr down cons up" so their performance and tree traversal path are the same;
however, they differ in the way programmer is thinking about the tree traversal problem, in the first approach we are
thinking in terms of pairs and traversing the tree pairwise, in the second we are thinking in terms of subtrees. Note
that in the second approach the lambda passed to map is itself calling "scale-tree" on subtree.

**** Notes
- Recursion is really powerful tool for hierarchical structures. If you name your abstractions properly, all you have to
  do is solve for the base cases and let closure take care of the rest. See Exercise [[./chapter-2/33-accumulate/33-accumulate.scm][2.35]].
*** Sequences as Conventional Interfaces
Use of "conventional interfaces" is a powerful design principle for working with data structures.

In section [[Formulating Abstractions with Higher Order Procedures][1.3]] we saw how program abstractions, implemented as higher-order procedures, can capture *common patterns in
programs* that deal with numerical data. Our ability to formulate analogous operations for working with compound data
depends crucially on the style in which we manipulate our data structures.

#+BEGIN_SRC scheme
(define (sum-odd-squares tree)
    (cond ((null? tree) 0)
          ((not (pair? tree))
          (if (odd? tree) (square tree) 0))
          (else (+ (sum-odd-squares (car tree))
                   (sum-odd-squares (cdr tree))))))

(define (even-fibs n)
    (define (next k)
        (if (> k n)
            nil
            (let ((f (fib k)))
                (if (even? f)
                (cons f (next (+ k 1)))
                (next (+ k 1))))))
    (next 0))
#+END_SRC

Despite the fact that these two procedures are structurally very different, a more abstract description of the two
computations reveals a great deal of similarity.

The first program:
   - enumerates the leaves of a tree;
   - filters them, selecting the odd ones;
   - squares each of the selected ones; and
   - accumulates the results using `+', starting with 0.

The second program:
   - enumerates the integers from 0 to n;
   - computes the Fibonacci number for each integer;
   - filters them, selecting the even ones; and
   - accumulates the results using `cons',  starting with the empty list.

A signal-processing engineer would find it natural to conceptualize these processes in terms of signals flowing through
a cascade of stages. However, our two procedures decompose the computations in a different way, spreading the
enumeration over the program and mingling it with the map, the filter, and the accumulation. If we could organize our
programs to make the signal-flow structure manifest in the procedures we write, this would increase the conceptual
clarity of the resulting code. The key to organizing programs so as to more clearly reflect the signal-flow structure is
to concentrate on the "signals" that flow from one stage in the process to the next. If we represent these signals as
lists, then we can use list operations to implement the processing at each of the stages. Therefore, we can rewrite
sum-odd-squares and even-fibs as:

#+BEGIN_SRC scheme
(define (filter predicate sequence)
  (cond ((null? sequence) nil)
        ((predicate (car sequence))
         (cons (car sequence)
               (filter predicate (cdr sequence))))
        (else (filter predicate (cdr sequence)))))

(define (accumulate op initial sequence)
  (if (null? sequence)
      initial
      (op (car sequence)
          (accumulate op initial (cdr sequence)))))

(define (enumerate-tree tree)
  (cond ((null? tree) nil)
        ((not (pair? tree)) (list tree))
        (else (append (enumerate-tree (car tree))
                      (enumerate-tree (cdr tree))))))

(define (enumerate-interval low high)
  (if (> low high)
      nil
      (cons low (enumerate-interval (+ low 1) high))))

(define (sum-odd-squares tree)
  (accumulate +
              0
              (map square
                   (filter odd?
                           (enumerate-tree tree)))))

(define (even-fibs n)
  (accumulate cons
              nil
              (filter even?
                      (map fib
                           (enumerate-interval 0 n)))))
#+END_SRC

The value of expressing programs as sequence operations is that this helps us make program designs that are modular,
that is, designs that are constructed by combining relatively independent pieces. We can encourage modular design by
providing a library of standard components together with a *conventional interface* for connecting the components in
flexible ways. Modular construction is a powerful strategy for controlling complexity in engineering design.

Sequences, implemented here as lists, serve as a *conventional interface* that permits us to combine processing modules.
Additionally, we can experiment with alternative representations of sequences, while leaving the overall design of our
programs intact.  We will exploit this capability in chapter 3, when we generalize the sequence-processing paradigm to
admit infinite sequences.

Note: Although the time and space complexity may increase from n to 4n or 5n, the resulting conceptual clarity and
modularity helps the programmer understand and write better. 
**** Notes
- If you think about it, all operations on a computer are ETL, right from assembly level to the topmost
  abstractions. See Exercise [[./chapter-2/33-accumulate/33-accumulate.scm][2.36]].
- You can obtain efficient solutions to problems with or without abstractions. The difference is that when you solve a
  problem without using any abstractions you start at the most basic level and the solution is as good as your
  logic/imagination/creativity etc. However, when you solve the same problem using available abstractions there are few
  advatages: 1. you think using only the abstractions until the topmost abstraction barrier and might solve the problem
  faster with a easy to understand solution. 2. you benefit from improvements to implementation of abstractions without
  paying in cost. 3. you don't reinvent the wheel, you focus on the problem at hand. 4. you don't solve the problems
  that have already been solved.; and there are some disadvantages: 1. you have to know and learn about the available
  abstractions. See Exercise [[./chapter-2/33-accumulate/33-accumulate.scm][2.36]], [[./chapter-2/37-matrices/37-matrices.scm][2.37]].
- Use post-order/recursion when you want to apply/perform operations on the current item after the result of application
  of operation on the rest of the items/successors is ready. Use pre-order/iteration when you want to apply/perform
  operations on the current item after result from application of operation on previous items/predecessors is
  available. See Exercise [[./chapter-2/38-fold-right-left/38-fold-right-left.scm][2.38]].
- Don't try to remember how a procedure works instead try to remember the properties it provides, the argument it
  accepts and its return type. Thus, clear documentation and naming are critical when defining abstractions.
- Consider the following Spark Scala example. In addition to constructors, selectors and preconditions you should also
  consider providing a procedure that transforms object to itself using the provided function. This helps in chaining
  calls. The ease of readability increases significantly from first to last version.
#+BEGIN_SRC scala
//first attempt
    val rowsWithDummyAudit = addAuditColumnsToRows(rows)
    val unionRows = performUnion(rowsWithDummyAudit, audittedRows)
    val rowsBeforeAsOfDate = removeFutureRows(unionRows, asOfDateTime)
    val rankedRow = rankRows(rowsBeforeAsOfDate)
    val topRankedRows = fetchTopRankedRows(rankedRow)
    val rowsWithoutDeletedRows = removeDeletedRowsBeforeDateTime(topRankedRows, asOfDateTime)
    val finalRows = removeColumns(rowsWithoutDeletedRows, Set(RANK_COL))
    val orderedFinalRows = finalRows.orderBy(orderCriteria map col: _*)

// to chain it.
    val orderedFinalRows2 =
      removeColumns(
        removeDeletedRowsBeforeDateTime(
          fetchTopRankedRows(
            rankRows(
              removeFutureRows(
                performUnion(
                  addAuditColumnsToRows(rows),
                  audittedRows),
                asOfDateTime))),
          asOfDateTime),
        Set(RANK_COL)).orderBy(orderCriteria map col: _*)

// chaining using transform
    val orderedFinalRows3 =
      removeColumns(
        removeDeletedRowsBeforeDateTime(
          removeFutureRows(
            performUnion(rows.transform(addAuditColumnsToRows), audittedRows),
            asOfDateTime)
            .transform(rankRows)
            .transform(fetchTopRankedRows),
          asOfDateTime),
        Set(RANK_COL)).orderBy(orderCriteria map col: _*)

//even better chaining using transform and lambdas
    val orderedFinalRows4 =
      rows.transform(addAuditColumnsToRows)
        .transform(dataFrame => { performUnion(dataFrame, audittedRows) })
        .transform(dataFrame => { removeFutureRows(dataFrame, asOfDateTime) })
        .transform(rankRows)
        .transform(fetchTopRankedRows)
        .transform(dataFrame => { removeDeletedRowsBeforeDateTime(dataFrame, asOfDateTime) })
        .transform(dataFrame => { removeColumns(dataFrame, Set(RANK_COL)) })
        .orderBy(orderCriteria map col: _*)
#+END_SRC

**** Nested Sequences

We can extend the sequence paradigm to include many computations that are commonly expressed using nested
loops. Consider this problem: Given a positive integer n, find all ordered pairs of distinct positive integers i and j,
where 1 <= j< i<= n, such that i + j is prime.

We can generate the sequence of pairs: For each integer i <= n, enumerate the integers j<i, and for each such i and j
generate the pair (i,j).

#+BEGIN_SRC scheme
(accumulate 
    append 
    nil
    (map (lambda (i)
             (map (lambda (j) (list i j))
                  (enumerate-interval 1 (- i 1))))
         (enumerate-interval 1 n)))
#+END_SRC

The combination of mapping and accumulating with 'append' is so common in this sort of program that we will isolate it
as a separate procedure:

#+BEGIN_SRC scheme
     (define (flatmap proc seq)
       (accumulate append nil (map proc seq)))

     ;;Above definition can be used to generate the same sequence of pairs for nested loop as follows:
     (flatmap
         (lambda (i)
             (map (lambda (j) (list i j))
                  (enumerate-interval 1 (- i 1))))
         (enumerate-interval 1 n))
#+END_SRC

All of this can be put together to generate prime-sum-pairs as follows:

#+BEGIN_SRC scheme
(define (prime-sum? pair)
    (prime? (+ (car pair) (cadr pair))))

(define (make-pair-sum pair)
    (list (car pair) (cadr pair) (+ (car pair) (cadr pair))))

(define (prime-sum-pairs n)
  (map make-pair-sum
       (filter prime-sum?
               (flatmap
                   (lambda (i)
                       (map (lambda (j) (list i j))
                            (enumerate-interval 1 (- i 1))))
                   (enumerate-interval 1 n)))))
#+END_SRC

Nested mappings are also useful for sequences other than those that enumerate intervals.  Suppose we wish to generate
all the permutations of a set S {1,2,3}. The idea is to recursively generate the sequence of permutations of S - x, and
adjoin x to the front of each one. This can be written as:

#+BEGIN_SRC scheme
(define (remove item sequence)
  (filter (lambda (x) (not (= x item)))
          sequence))

(define (permutations s)
  (if (null? s)                    ; empty set?
      (list nil)                   ; sequence containing empty set
      (flatmap (lambda (x)
                 (map (lambda (p) (cons x p))
                      (permutations (remove x s))))
               s)))
#+END_SRC

Notice how this strategy reduces the problem of generating permutations of S to the problem of generating the
permutations of sets with fewer elements than S.

*** Example: A Picture Language


* Miscellaneous

* References
- https://mitpress.mit.edu/sites/default/files/sicp/index.html
- https://sarabander.github.io/sicp/html/index.xhtml
- http://zv.github.io/sicp-in-texinfo
- https://xuanji.appspot.com/isicp/index.html
- https://www.neilvandyke.org/sicp-texi/
- https://github.com/webframp/sicp-info

* SICP Info
** Install
#+BEGIN_SRC bash
mv ~/Downloads/sicp.info /usr/local/share/info/
install-info /usr/local/share/info/sicp.info --dir-file="/usr/local/share/info/dir"
#+END_SRC
** Usage
*** Option 1
- Open file "/usr/local/share/info/sicp.info" in emacs.
- emacs will open it in info mode.
*** Option 2
- "C-h i"
- This will open info InfoMode, search for SICP.
